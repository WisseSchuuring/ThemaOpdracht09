---
title: "ThemaOpdracht09Log"
author: "Wisse Schuuring"
date: "9/14/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)

```

## Day 1 Tuesday 14th of September, 2021

From the github of michielnoback chosen the "Crab body metrics" dataset.
Downloaded the dataset from https://www.kaggle.com/inputblackboxoutput/crab-body-metrics

Description
This dataset has 200 rows and 8 columns, describing 5 morphological measurements on 50 crabs each of two colour forms and both sexes, of the species Leptograpsus variegatus collected at Fremantle, W. Australia.

SP = Species: "B" or "O" for blue or orange.
sex = M- Male F - Female
index = Unique row identifier
FL = Frontal lobe size (mm)
RW = Rear width (mm)
CL = Carapace length (mm)
CW = Carapace width (mm)
BD = Body depth (mm)

Source
Campbell, N.A. and Mahon, R.J. (1974) A multivariate study of variation in two species of rock crab of genus Leptograpsus. Australian Journal of Zoology 22, 417â€“425.

References
Venables, W. N. and Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth edition. Springer.

Created a Github account along with a repo, and pushed the dataset and log file along with everything else "git" into it.

Read the csv file and attempted to create a handful of plots with its contents.

Successfully plotted the crabs' Body Depth in relation to its Rear Width, and comparing it with its species and sex.

```{r}
#Read in the libraries
library(ggplot2)

#Read in the dataset
CrabData <- read.csv(file = 'data/CrabData.csv')
CrabData 

#Give the 5 values of the dataset
summary(CrabData)

CrabData <- CrabData %>% mutate(sp = factor(sp, levels = c("B","O"), labels = c("Blue Leptograspus","Orange Leptograspus")))

#Create a plot of both species
ggplot(CrabData, aes(y = RW, x = BD, color=sp)) +
  geom_point() +
  scale_x_continuous() +
  geom_jitter() +
  geom_smooth() +
  scale_color_manual(values=c("Blue","Orange"))


#Create a boxplot
boxplot(CrabData$RW, CrabData$BD)

```



# Day 2 Wednesday 15th of September, 2021



Successfully created two separate plots for the two species.

```{r}
#Read in the libraries
library(ggplot2)
library(dplyr)

#Read in the dataset
CrabData <- read.csv(file = 'data/CrabData.csv')

#Filter the datasets on their species
CrabDataB <- filter(CrabData, sp == "B")
CrabDataO <- filter(CrabData, sp == "O")

#Give the 5 values of the dataset
#summary(CrabData)

#Create a plot of both species
plot1 <- ggplot(CrabData, aes(y = RW, x = BD, color=sex, shape = sp)) +
  geom_point() +
  scale_x_continuous() +
  geom_jitter() +
  geom_smooth(method = " loess") +
  scale_color_manual(values=c("Blue","Orange"))

#Create a plot of only the blue species 
plot2 <- ggplot(CrabDataB, aes(y = RW, x = BD)) +
  geom_point() +
  scale_x_continuous() +
  geom_jitter() +
  geom_smooth(col = "blue")

#Create a plot of only the orange species
plot3 <- ggplot(CrabDataO, aes(y = RW, x = BD)) +
  geom_point() +
  scale_x_continuous() +
  geom_jitter() +
  geom_smooth(col = "orange")

#Create a boxplot
plot4 <- boxplot(CrabData$RW, CrabData$BD)

```
The first canonical variate, which differentiates between the two species, represents a contrast
between the carapace width relative to the width of the front lip and the depth of the body;
the blue-form species has a greater relative carapace width than has the orange form. 

```{r}
#Create a plot showing the carapace width against the frontal lobe size of the two species
plot5 <- ggplot(CrabData, aes(y=CW, x=FL, col=sp)) +
  geom_point(alpha=0.5) +
  geom_jitter() +
  scale_colour_manual(values = c("Blue","Orange")) +
  xlab("Frontal Lobe Size (mm)") +
  ylab("Crapace Width (mm)") +
  geom_smooth(method="loess", formula = y ~ x)

```
The second canonical variate, which presents a contrast between the rear width and the carapace
length, identifies males and females within each species; males have a greater relative carapace
length than have females. 

```{r}
plot6 <- ggplot(CrabData, aes(y=RW, x=CL, col=sex)) +
  geom_point() +
  geom_jitter() +
  scale_colour_manual(values = c("Red","Dark Green"))
```

All individuals, including 20 not used in the study, were correctly identified for colour form.
The clear separation of the blue and orange forms achieved by canonical analysis supports the
previously determined specific status of the two forms. 

```{r}
codebook <- read.csv(file = "data/codebook.csv")
knitr::kable(codebook)
```
Day 3  21st of September

Onderzoeksvraag bedenken

Is it possible to create an algorithm which, when given the Frontal Lobe Size and Carapace Width of a purple rock crab, determine whether or not it belongs to the blue or orange species?

Started with creating an EDA. Through analyzing the given data, along with comparison and edits of the dataset itself. With this, I determined that the best identifiers for species difference are the Carapace Width and Frontal Lobe Size.

Day 4 23/09/2021

Beschrijvingen gegeven aan figuren van de dataset. Begonnen met PCA's te maken.


Day 5 28th of September

day 6 wednesday 6th of october

created many graphs showing the difference in body size between the orange and blue subspecies, and by comparison decided Carapace Width and Frontal Lobe Size were the best values to use for determine which crab belongs to which species, upon which the machine learning algorithm can be built. 

Using this newly created CleanData.csv file in Weka 3.8, by first removing the identifier attribute by selecting it and pressing 'remove', one can move over to the classify window. There, first running a ZeroR with the 'training set' test option selected will reveal the accuracy of the algorithm to be 50%. this makes sense, as there is an even distribution of both blue and orange purple rock crabs in the dataset. with ZeroR, the algorithm will only look at a single attribute and take it as truth. Simply put, the system will assume every identified attribute shall be the one that is most prominent. This dataset containing 100 blue and 100 orange purple rock crabs, it picks one, and assumes all others are the same as the one it picked. Therefore, a 50% accuracy is expected, as 100/200 * 100 = 50%.

next up using oneR with the 'training set' test option gives an accuracy of 76.5%, with 94 True positives, 6 False positives, 59 True negatives and lastly 41 False negatives. 

Utilising the tree classifier J48, firstly an unpruned tree was created with the test option cross-validation activated with a fold of 5. 

Utilising J48 with the same discriminator, unpruned set to False and test option set to 'training set' results in an accuracy of 96.5%, with 99 True positives, 1 False positive, 94 True negatives and 6 False negatives. setting the unpruned to True results in the exact same tree.

Now changing the test option to 'cross-validation' with a fold value of 10, gives an accuracy of 88%. While worse, it is still surprisingly accurate. after changing the seed to 2, it gives an accuracy of 91%, containing 94 TP, 6 FP, 88 TN and 12 FN.

day 7 7th of october

Started to investigate the performance of different machine learning algorithms.

```{r, fig.cap="A table showing the speed and accuracy of the classification method, along with the confusion matrix"}
OldWekaResults <- read.csv(file = "data/OldWekaResults.csv")
knitr::kable(OldWekaResults)
```

these results showed that Simple Logistic works almost perfectly. Upon suggestion I have made a change to the cleaned data file, removing the unnecessary gender value and opting for body depth instead, for it has a larger impact on deciding whether a creature belongs to one species or the other. 

```{r, fig.cap="A table showing the speed and accuracy of the classification method, along with the confusion matrix"}
WekaResults <- read.csv(file = "data/WekaResults.csv")
knitr::kable(WekaResults) 
```

This results in an accuracy of 100%, perfection.

12th of October

Using Weka's experiment enviroment, I created a new experiment, in which I placed my CleanData.csv file, and let three algorithms run on it. ZeroR for testing, my previously discovered perfect algorithm of SimpleLogistics and lastly Ibk, for it had the second highest score, having a NN value of 3. Letting it run for 100 repetitions and opening the finalised test in the analyse window gives the following result. 

```{r, fig.cap="A table showing the speed and accuracy of the classification method, along with the confusion matrix"}
ExperimentResults <- read.csv(file = "data/ExperimentResults.csv")
knitr::kable(ExperimentResults)
```

With the highest accuracy and the smalles significant (not counting ZeroR) SimpleLogistic shows to be the better classification method. 

Next up I attempted to run 3 ensemble learning meta, those being bagging, stacking and boosting. Bagging is when a classifier method is reused, however the dataset is bootstrapped, meaning the meta runs the same algorithm, just on slightly modified versions of the dataset each repeat. Boosting is when the selected algorithm is run once on a test dataset, after which the meta increases the weight of any mistakes (False positives, False negatives), followed by another run. Any mistakes made in the second run are increased in weight again, and this process is repeated for as many repetitions that are specified. Lastly stacking is when multiple algorithms look at the worth of the output of the individual classification method, after which the impact of said method is weighed against the others. The classification method with the higher accuracy has a bigger weight, while a less accurate method has less impact. 
